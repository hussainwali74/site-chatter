hey this is Lance from Lang chain we've seen a lot of interest in langra over the last months and in particular we've seen kind of clustering around a few popular and common use cases so we're launching templates today to give template applications across some of these popular use cases that can be easily extended and easily configured but give you a nice starting point so you don't have to go from scratch building something that is fairly common that many other people have built and configured for their own uses so I wonder show one just to give you a sense for how templates work in general so the problem statement for this particular template is structured results from some kind of open-ended research task here's a common problem statement I have a database I have a spreadsheet that I want to populate with results from open-ended research that research is often for example from the web but it could be other research sources so it's basically the problem of going from unstructured research to a structured output that fits into a CSV the spreadsheet or database format that's really it so what's going to happen is as a user when I'm interact with my agent I specify a topic I specify an output schema the agent goes and does all the research for me and produces results in the schema that I specify that's really it so I'm going to go ahead and walk you through the functionality here really quickly and then we'll go through the details a it later so I want to go ahead and grab this so all I'm going to do is just copy this over I clone it and I open it up in my IDE so here we are here's the code here's the Remy we're just looking at so if I go back to the readme the first thing I need to do to get this running is create an EnV file okay I go back here so you can see we have this EnV example you're going to set a few things TBL API key Langs Smith project and your llm now what are these different things so Tav and I'll go ahead and show you that right now let's open that up here Tav is a very nice web search tool that I tend to like so here's a website for it it's a search API for LMS and rag now here's a nice things about it it's easy to set up it has a generous free tier and it kind of just works um now there's other search tools out there you can easily configure this to use whatever Search tool you want tabl is one that I tend to like and so that's why it's kind of recommended here Langs Smith project this sets the project for Langs Smith that all of your agent runs will log to now Langs Smith is Lang Chain's platform for observability tracing monitoring evaluation and you're going to see here it's very useful for debugging and monitoring our agent Behavior now LM of choice you can choose any model you want of course these are just some example keys that it's kind of by default set to work with but you can extend this very easily so the first thing I do is I'm going to create my EnV file as noted in the readme here and I've done that I now have my EnV file now that's actually all you need to get up and running with this agent template so if you look at this Lang graph. Json this is a config file that langra studio uses Lang graph studio is an IDE for Lang graph that gives you very easy and nice way to run agents look at the results and kind of understand the internal behavior of the agent so all this is doing is basically it's naming a graph that I want to open up in L graph studio and it's specifying The Source or the path to the compile graph so SRC enrichment agent graph. piy graph is actually the raw compile graph right here that's it so it's pretty nice this is all we need to actually get up and running in studio so I'm in studio now let's just go ahead and open up that directory so here I am this is my data enrichment directory you can see the Lang after dayon here the EnV files present here I just click open and here we are this is what we see once we go ahead and load our graph you can see it's named agent that again comes from the config file l. Json we name this agent we give the location of the the compile graph and here's our graph nice visualization these are the nodes these Arrow are the edges cool now you can see we can very easily input two things here topic extraction schema okay we also have this configurable this allows us to input a bunch of different things Max Loops search results model name prompt we'll talk through what all those mean a little bit later I'm not going to touch those for now but I just want to show you it's all here so you can easily configure the functionality of your graph and this is where you're going to input now let's go back to the read me and I'll show you some example inputs that we can use for the research task here I'm interested in LM training I want to know about the top five chip providers for LM training I pass that as my topic and this is where I specify an extraction schema so this is kind of interesting the extraction schema is just a Json object and as long as this is valid Json we can use it there it is now let's go ahead and run this now I just want to rewind a little bit what have we done we've all we've done is create that EnV file that has basically my tab API key as well as API key for whatever model I want to use that's all we need to do I open this in studio run so now agent's running nice so we finished running now I'll show you something really cool in studio I can just scroll down here and I actually can walk through the entire process of my agent as it ran so I can see each step tool call is all the results from the particular tool call goes back to the model finally goes to reflection step back tool call agent model final reflection and and we get a good result now we're going to walk through what each of these nodes are doing in a little bit more detail but this is a really nice way to just browse the trajectory of your agent everything that happened so pretty cool now we also can look at here's actually the result of our research process you can see we have this list of companies here's Nvidia it gives us future outlook key Powers market share name Technologies it's pretty cool these are all things we specified in that extraction scheme that we want for every company in our list so you can see this is what you get from the agent when you run it and we've run this in the ID linecraft studio and this gives us a really nice way to kind of browse through the full trajectory of our agent what it did and what we get out this is actually how to use the agent now we we can dig a little bit further into what it actually did under the hood now to understand what it did under the hood I want to walk through each step in studio here and then go over to the code and kind of correspondingly explain what's happening in the code so we start here's the inputs we provided top five chip providers for LM training and here's the schema we care about now we went then to call agent model okay now here's where things get interesting let's go look at the code so here's call agent model you can see it's defined in graph. piy and here's the key intuition this agent is basically an llm as we defined initially by default look at this configuration. piy the default configuration for the llm is going to be anthropic we set the API key in our EnV files we can use anthropic without a problem in our configurable here you can change the model name if you'd like and the read me talks about other models you can choose so that just gives you a sense that we we've set our llm now in graph. piy we take that llm and we bind a few different tools here's the key point we bind tools search info tool scrape website so what are these things if you open up tools the you can see the definition for two of these so one is search this is Tav we talked about before this is a very nice Search tool basically it'll call tavali it's going to return a bunch of summaries of websites related to the question that's where you get from tap we also have the scrape website tool this will take a URL and actually grab the contents of the website so scrape it and format the results and you see this info prompt into the schema that we specified so basically it's kind of scraping a full website and extracting the results into our desired schema so that's just kind of the second tool now this final thing info tool this is a tool that we actually Define here in this node definition and this is actually the final result of our research process this is going to be called once we've gathered all the relevant info and it's going to basically be like a structured output tool that will produce a final output in the desired schema so that's really what's happening with this info tool so basically we have a chat model that we've initialized through config we've bound these three tools and we let it call Tools in a loop and that's what you see here agent model now what happened is it went to Tool it made a decision to call the Search tool first with our query makes a lot of sense here's our question let's look get some websites related to that question the Search tool runs tab these are all the nice results we get from the tab search you can see kind of a summary and a URL summary URL pretty cool huh that's all nice see a lot of results and again you can configure this we set by default return 10 results that's why we're getting quite a bit of search results here so this then goes back to the model I want to make one little interesting point here this Loop step is tracking the number of times we call a tool and go back to the model so we've done one and this is going to increment every time we go back to call model we make a decision to call second tool we call search again and it looks like it call search with a slightly different query okay so we're letting the agent kind of operate in an open-ended way use these tools that it sees fit in its research process so it's calling the Search tool again it gets a little bit more resources from tavali here cool now this is pretty interesting it says I've gathered enough information and I'm going to call that info tool to produce a report of my final results pretty nice now recall we've only called The Tool twice we've called search twice and now the agent says okay let's go ahead and format my final results so we get look at this this is pretty cool future outlook key Powers market share name technology pretty good okay so we get that from those two search results that we've accumulated and we now are going to go to reflect so let's go and look at the code and see what reflect is doing so the reflect node is defined here and really here's the punchline it's going to review the results of the research and determine are they satisfactory or not now this structured object info is satisfactory is going to be a data model that this particular note is going to use to kind of grade the final output so you can see in particular this is satisfactory feels important give reasoning and provide a value indicating whether the result is satisfactory okay and so this is forcing a model to basically reflect on the results deem them to be satisfactory per some criteria or not now the criteria is going to be specified in our prompt here are the results good um are the URLs relevant to the topic and so forth and you can read through all this as you see fit but the point is this reflection is going to look at the results from the research and assess them as relevant I we satisfactory now here's what's pretty cool we can look at what happens in studio it deems it to be unsatisfactory and it gives a bunch of reasons so it gives you some nice feedback gives more specific estimates pretty cool right now we go back to the agent model we did a reflection because that key is unsat is unsatisfactory true we go back and call the agent the agent continues its research process using that reflection feedback it goes as it calls the Search tool again we get the search results further and then it recalls the the info tool to produce a new report based upon these updated search results that hopefully address the feedback from reflect cool there it is this gets passed to [Music] reflect and now reflect deems the information is comprehensive up to dat and covers major topics provided so now our reflection is deeming it to be satisfactory and we end that's it so that's kind of the basic functionality of our agent walking through both the code as well as the trajectory in studio you can see how the two kind of play really nicely together I'm going to show you one other pretty cool thing I so because we set our langth project here every time we run our agent in studio for example we locked to this project in lsmith so I can open up lsmith and here's a particular Trace we just ran I can see my overall token usage I can see overall latency I look I can look at every single uh model invocation as well as tool call and this gives the whole tror agent which we just looked at in studio so I don't want to rehash everything but it's also Sav for you in Trace format for propertuity in Langs Smith so this is a very nice thing that I often use complimentary with studio now I want to show you one other really nice trick here so we've been using Studio and you're going to see something kind of interesting here we have this URL okay so what's going on here so studio is basically taking our code which is specified here okay and it packages it up and it uses the langra API as the backend so what's really happening is the langra API is the back end serving the front end which is this really nice Studio UI that's all great but what if we actually don't want to use a studio UI what if we want to interact with our graph directly you can do that I copy over this okay and I'm going to go ahead and open up a Jupiter notebook cool so now Jupiter is open I click on Notebook I go to testing and here we are so all I need to do I can use a langra STK to connect with my agent running in studio I just copy that URL over I'm going to use langra SDK get client to go ahead and get my graph okay so I'm just going to grab again this is named agent so all I need to do is supply my input here's the schema we want to work with now all I can do is I can go ahead and optionally set a different llm here in this case I'll use GPD 40 I'm going to create a new thread which is is going to basically track the state of my agent as it runs and what I'm going to do is simply call client runs. stream I pass in my thread that assistant ID is Agent which we just showed I provide my input and note that I provide this configurable field where I set the model name as llm now let me kind of Backtrack on that one a little bit recall look at our code configur up high we set a bunch of configurations model name prompt Max search results and so forth you can read about all these in the configuration file in studio we access them via this configurable when using the API directly just pass them again as configurable here and make sure you specify the correct configuration name in this case I pick model name the default was anthropic I want to override that and use open AI for this particular run and I'm going to go ahead and stream this is values this is basically the state of the graph at every step okay that's really all it's going to go on now I can kick that off right here cool so that ran now I'll show you something kind of cool here this printed out the whole state and obviously this is very verbose this is kind of the state across the entire trajectory of the agent if I want to get the final or current state of my agent after everything's run all I need to do is basically call this get state from the thread remember this thread which I created right here is basically saving the state of My Graph at every step pretty nice and pass in the thread ID I can get the current state now this current state let's just look at it quickly this is just going to be you know you can see it's a big dick look at the values here now let's go ahead and just kind of look at info now remember info is the final report that we're producing there we go pretty nice I format this as markdown so we can see in the notebook really nicely so you know again my question was um go all the way back up top five chip providers for alum training my desired schema was this and indeed the output aderes to just close this down the desired schema pretty cool Nvidia Technologies share keyow future outlook pretty nice so there you go so let's kind of Pop all the way back out and explain what we did here and all the different kind of tricks and niceties that we have available to us using templates summarize templates provide you a very quick way to get started with L graph for specific applications they are very easily configurable and adaptable for your use case like we showed initially you can spin them up really fast in studio with very little work all I do is create an EnV file and I can run this by default out of the box okay if I want to I can modify various parameters here just via the studio UI and you can go ahead and look in configuration. to examine what all those parameters are okay so that's kind of step one now every time I run my agent I also log the trace to Langs Smith so I have by default in the NVA example I've set a project data enrichment and because of that traces for my agent are all logged to that project so I have a nice record of everything I've done already by default set up for me and lsmith now if I don't want to use a studio to interact with my template I can also interact directly with the API if I want to run that locally all I need to do is spin up Studio copy this link I showed in the notebook how we can then access it using the Langs Smith SDK or the Lang graph SDK right here connect to it pass in the inputs just like we did Studio same deal so that's a way you can interact directly with the API you don't have to use studio now finally I'll highlight one thing you might think about is how could I actually deploy this so in the notebook here we we work with the langra API that served locally via Studio you can see via this URL here but if you actually want to deploy you can even go one step further and use langra cloud I provide a link at the end of this notebook where you can investigate that further um but there's a lot of cool things you can do with lra class Cloud uh for example this API is hosted for you and then you can build for example a front end and you know basically it is a fully hosted service for Lang graph agents and I'll let you kind of read about that on your own if that's of interest but this is kind of showing you how you can go all the way from I'll go back to the repo a template to very quickly up and running in studio if you just want to play around easily configurable via Studio here easily interacted with via the API here as we shown the notebook and you can even go all the way to deployment so that gives you an overview of templates how I can use them in a few different ways and um have fun and leave any comments in the video and we will certainly uh address them thanks